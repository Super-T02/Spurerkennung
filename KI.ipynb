{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import scipy.special\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from enum import Enum\n",
    "from scipy.spatial.distance import cdist\n",
    "import time\n",
    "\n",
    "from model.model import parsingNet\n",
    "\n",
    "lane_colors = [(0,0,255),(0,255,0),(255,0,0)]\n",
    "\n",
    "tusimple_row_anchor = [ 64,  68,  72,  76,  80,  84,  88,  92,  96, 100, 104, 108, 112,\n",
    "\t\t\t116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164,\n",
    "\t\t\t168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216,\n",
    "\t\t\t220, 224, 228, 232, 236, 240, 244, 248, 252, 256, 260, 264, 268,\n",
    "\t\t\t272, 276, 280, 284]\n",
    "\n",
    "model_path = \"model/tusimple_18.pth\"\n",
    "useGPU = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConfig():\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tself.imgWidth = 1280\n",
    "\t\tself.imgHeight = 720\n",
    "\t\tself.row_anchor = tusimple_row_anchor\n",
    "\t\tself.griding_num = 100\n",
    "\t\tself.cls_num_per_lane = 56\n",
    "\n",
    "class LaneDetectiion():\n",
    "    def __init__(self, model_path, useGPU=False):\n",
    "\n",
    "        self.useGPU = useGPU\n",
    "\n",
    "        # Load model configuration based on the model type\n",
    "        self.cfg = ModelConfig()\n",
    "\n",
    "        # Initialize model\n",
    "        self.model = self.buildModel(model_path, self.cfg, useGPU)\n",
    "\n",
    "        # Initialize image transformation\n",
    "        self.img_transform = self.imageTransformation()\n",
    "    \n",
    "    def buildModel(self,model_path, cfg, useGPU):\n",
    "        # Load the model architecture\n",
    "        net = parsingNet(pretrained = False, backbone='18', cls_dim = (cfg.griding_num+1,cfg.cls_num_per_lane,4))\n",
    "\n",
    "\n",
    "        # Load the weights from the downloaded model\n",
    "        if useGPU:\n",
    "            net = net.cuda()\n",
    "            state_dict = torch.load(model_path, map_location='cuda')['model'] # CUDA\n",
    "        else:\n",
    "            state_dict = torch.load(model_path, map_location='cpu')['model'] # CPU\n",
    "\n",
    "        compatible_state_dict = {}\n",
    "        for k, v in state_dict.items():\n",
    "            if 'module.' in k:\n",
    "                compatible_state_dict[k[7:]] = v\n",
    "            else:\n",
    "                compatible_state_dict[k] = v\n",
    "\n",
    "        # Load the weights into the model\n",
    "        net.load_state_dict(compatible_state_dict, strict=False)\n",
    "        net.eval()\n",
    "\n",
    "        return net\n",
    "\n",
    "    def imageTransformation(self):\n",
    "\t\t# Create transfom operation to resize and normalize the input images\n",
    "        img_transforms = transforms.Compose([\n",
    "\t\t\ttransforms.Resize((288, 800)),\n",
    "\t\t\ttransforms.ToTensor(),\n",
    "\t\t\ttransforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "\t\t])\n",
    "\n",
    "        return img_transforms\n",
    "\n",
    "    def detectLanes(self, image, draw_points=True):\n",
    "\n",
    "        input_tensor = self.preprocess(image)\n",
    "\n",
    "        # Perform Ai on img\n",
    "        with torch.no_grad():\n",
    "            output = self.model(input_tensor)\n",
    "\n",
    "        # Process output data\n",
    "        self.lanes_points, self.lanes_detected = self.process_output(output, self.cfg)\n",
    "\n",
    "\n",
    "        # Draw depth image\n",
    "        visualization_img = self.drawLanes(image, self.lanes_points, self.lanes_detected, self.cfg, draw_points)\n",
    "\n",
    "        return visualization_img\n",
    "\n",
    "    def preprocess(self, img):\n",
    "        # Transform the image for inference\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_pil = Image.fromarray(img)\n",
    "        input_img = self.img_transform(img_pil)\n",
    "        input_tensor = input_img[None, ...]\n",
    "\n",
    "        if self.useGPU:\n",
    "            if not torch.backends.mps.is_built():\n",
    "                input_tensor = input_tensor.cuda()\n",
    "\n",
    "        return input_tensor\n",
    "\n",
    "    def process_output(self,output, cfg):\t\t\n",
    "        # Parse the output of the model\n",
    "        processed_output = output[0].data.cpu().numpy()\n",
    "        processed_output = processed_output[:, ::-1, :]\n",
    "        prob = scipy.special.softmax(processed_output[:-1, :, :], axis=0)\n",
    "        idx = np.arange(cfg.griding_num) + 1\n",
    "        idx = idx.reshape(-1, 1, 1)\n",
    "        loc = np.sum(prob * idx, axis=0)\n",
    "        processed_output = np.argmax(processed_output, axis=0)\n",
    "        loc[processed_output == cfg.griding_num] = 0\n",
    "        processed_output = loc\n",
    "\n",
    "\n",
    "        col_sample = np.linspace(0, 800 - 1, cfg.griding_num)\n",
    "        col_sample_w = col_sample[1] - col_sample[0]\n",
    "\n",
    "        lanes_points = []\n",
    "        lanes_detected = []\n",
    "\n",
    "        max_lanes = processed_output.shape[1]\n",
    "        for lane_num in range(max_lanes):\n",
    "            lane_points = []\n",
    "            # Check if there are any points detected in the lane\n",
    "            if np.sum(processed_output[:, lane_num] != 0) > 2:\n",
    "\n",
    "                lanes_detected.append(True)\n",
    "\n",
    "                # Process the first 26 points of each lane\n",
    "                for point_num in range(processed_output.shape[0]):\n",
    "                    if point_num > 26:\n",
    "                        pass\n",
    "                    else:\n",
    "                        if processed_output[point_num, lane_num] > 0:\n",
    "                            lane_point = [int(processed_output[point_num, lane_num] * col_sample_w * cfg.imgWidth / 800) - 1, int(cfg.imgHeight * (cfg.row_anchor[cfg.cls_num_per_lane-1-point_num]/288)) - 1 ]\n",
    "                            lane_points.append(lane_point)\n",
    "                            \n",
    "            else:\n",
    "                lanes_detected.append(False)\n",
    "\n",
    "            lanes_points.append(lane_points)\n",
    "        return np.array(lanes_points), np.array(lanes_detected)\n",
    "        \n",
    "    def drawLanes(self,input_img, lanes_points, lanes_detected, cfg, draw_points=True):\n",
    "        # Write the detected line points in the image\n",
    "        visualization_img = cv2.resize(input_img, (cfg.imgWidth, cfg.imgHeight), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "        # Draw a mask for the current lane\n",
    "        if(lanes_detected[1] and lanes_detected[2]):\n",
    "            lane_segment_img = visualization_img.copy()\n",
    "            \n",
    "            cv2.fillPoly(lane_segment_img, pts = [np.vstack((lanes_points[1],np.flipud(lanes_points[2])))], color =(255,191,0))\n",
    "            visualization_img = cv2.addWeighted(visualization_img, 0.7, lane_segment_img, 0.3, 0)\n",
    "\n",
    "        if(draw_points):\n",
    "            for lane_num,lane_points in enumerate(lanes_points):\n",
    "                if lane_num > 2:\n",
    "                    break\n",
    "                for lane_point in lane_points:\n",
    "                    cv2.circle(visualization_img, (lane_point[0],lane_point[1]), 3, lane_colors[lane_num], -1)\n",
    "\n",
    "        return visualization_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benny\\AppData\\Local\\Temp\\ipykernel_21044\\3506178380.py:129: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(lanes_points), np.array(lanes_detected)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\drawing.cpp:2396: error: (-215:Assertion failed) p.checkVector(2, CV_32S) >= 0 in function 'cv::fillPoly'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m \t\u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39mif\u001b[39;00m ret:\t\n\u001b[1;32m---> 32\u001b[0m \toutput_img \u001b[39m=\u001b[39m lane_detector\u001b[39m.\u001b[39;49mdetectLanes(frame)\n\u001b[0;32m     34\u001b[0m \tnew_frame_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     36\u001b[0m \t\u001b[39m# Calculate Frame Rate\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [11], line 72\u001b[0m, in \u001b[0;36mLaneDetectiion.detectLanes\u001b[1;34m(self, image, draw_points)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlanes_points, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlanes_detected \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_output(output, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg)\n\u001b[0;32m     71\u001b[0m \u001b[39m# Draw depth image\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m visualization_img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdrawLanes(image, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlanes_points, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlanes_detected, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcfg, draw_points)\n\u001b[0;32m     74\u001b[0m \u001b[39mreturn\u001b[39;00m visualization_img\n",
      "Cell \u001b[1;32mIn [11], line 139\u001b[0m, in \u001b[0;36mLaneDetectiion.drawLanes\u001b[1;34m(self, input_img, lanes_points, lanes_detected, cfg, draw_points)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mif\u001b[39;00m(lanes_detected[\u001b[39m1\u001b[39m] \u001b[39mand\u001b[39;00m lanes_detected[\u001b[39m2\u001b[39m]):\n\u001b[0;32m    137\u001b[0m     lane_segment_img \u001b[39m=\u001b[39m visualization_img\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m--> 139\u001b[0m     cv2\u001b[39m.\u001b[39;49mfillPoly(lane_segment_img, pts \u001b[39m=\u001b[39;49m [np\u001b[39m.\u001b[39;49mvstack((lanes_points[\u001b[39m1\u001b[39;49m],np\u001b[39m.\u001b[39;49mflipud(lanes_points[\u001b[39m2\u001b[39;49m])))], color \u001b[39m=\u001b[39;49m(\u001b[39m255\u001b[39;49m,\u001b[39m191\u001b[39;49m,\u001b[39m0\u001b[39;49m))\n\u001b[0;32m    140\u001b[0m     visualization_img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39maddWeighted(visualization_img, \u001b[39m0.7\u001b[39m, lane_segment_img, \u001b[39m0.3\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[0;32m    142\u001b[0m \u001b[39mif\u001b[39;00m(draw_points):\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\drawing.cpp:2396: error: (-215:Assertion failed) p.checkVector(2, CV_32S) >= 0 in function 'cv::fillPoly'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mDer Kernel ist beim Ausführen von Code in der aktuellen Zelle oder einer vorherigen Zelle abgestürzt. Bitte überprüfen Sie den Code in der/den Zelle(n), um eine mögliche Fehlerursache zu identifizieren. Klicken Sie <a href='https://aka.ms/vscodeJupyterKernelCrash'>hier</a>, um weitere Informationen zu erhalten. Weitere Details finden Sie in Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "def _calcFPS(prev_frame_time, new_frame_time):\n",
    "\t# Calculate Frame Rate\n",
    "\tfps = 1/(new_frame_time-prev_frame_time)\n",
    "\tprev_frame_time = new_frame_time\n",
    "\tfps = int(fps)\n",
    "\tfps = str(fps)\n",
    "\n",
    "\treturn fps, prev_frame_time\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "\n",
    "cap = cv2.VideoCapture(\"img/Udacity/project_video.mp4\")\n",
    "\n",
    "# Initialize lane detection model\n",
    "lane_detector = LaneDetectiion(model_path, useGPU)\n",
    "\n",
    "cv2.namedWindow(\"Video\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "ret, frame = cap.read()\n",
    "while ret:\n",
    "\ttry:\n",
    "\t\t# Read frame from the video\n",
    "\t\tret, frame = cap.read()\n",
    "\t\t\n",
    "\texcept:\n",
    "\t\tcontinue\n",
    "\n",
    "\tif ret:\t\n",
    "\t\toutput_img = lane_detector.detectLanes(frame)\n",
    "\n",
    "\t\tnew_frame_time = time.time()\n",
    "\n",
    "\t\t# Calculate Frame Rate\n",
    "\t\tfps, prev_frame_time = _calcFPS(prev_frame_time, new_frame_time)\n",
    "\n",
    "\t\t# Put fps on the screen\n",
    "\t\tcv2.putText(output_img, fps, (7, 21), font, 1, (100, 100, 100), 2, cv2.LINE_AA)\n",
    "\n",
    "\t\tcv2.imshow(\"Video\", output_img)\n",
    "\n",
    "\telse:\n",
    "\t\tbreak\n",
    "\n",
    "\t# Press key q to stop\n",
    "\tif cv2.waitKey(1) == ord('q'):\n",
    "\t\tbreak\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ressources:\n",
    "\n",
    "Model von: https://github.com/cfzd/Ultra-Fast-Lane-Detection <br>\n",
    "Direkt Dwonload: https://drive.google.com/file/d/1WCYyur5ZaWczH15ecmeDowrW30xcLrCn/view?usp=sharing\n",
    "\n",
    "\n",
    "Hilflibaries: https://github.com/ibaiGorordo/Ultrafast-Lane-Detection-Inference-Pytorch-/tree/main/ultrafastLaneDetector"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('Bildverarbeitung')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0a3075694810a7bb993da77f9c64a653d81b0695ead550ad875383aa24f0556"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
